---
title: "Calculating dimensions of stability using species abundance data in response to multiple stressors"
author: "Lydia White"
date: "`r Sys.Date()`"
output:
   html_document:
     toc: true
     toc_float: true
     code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE)

```

Workflow for Figure 3a in Rush paper, submitted to oikos 

```{r input data}
library(readr)
data <- read_csv(here::here("data","RUSH_MACRO_Concise.csv"))

```

```{r libraries, message=FALSE}
library(tidyverse)
library(vegan)
library(lsmeans)
library(emmeans)
library(car)
library(lme4)
library(lmerTest)
library(ggh4x)
library(patchwork)
library(ggpubr)
library(rstatix)
```

# Data format

Treatments:
A	Algae
B	Algae & Grazers
C	Algae, Grazers & Whelks 
D	Uncaged control plot 

N0	No Nutrients 
N1	Enriched with Nutrients 
S0	No Sediment
S1	Sediment added

Functional responses are based on total percentage cover of all algal species as a proxy for biomass. Total percentage cover values often exceeded 100% due to the multi-layered nature of macroalgal communities. 

```{r summarise cover data, }
data$Plot <- gsub("24\\*", "100", data$Plot)

cols <-data %>% select(Fuc_Ves:Hilden) # columns of interest i.e. species

functional<- data%>%
  mutate_if(is.numeric, ~replace(., is.na(.), 0))%>%
   mutate(sum = rowSums(cols)) %>%
   select(Time:Treatment,sum) %>%
    filter(Time > 5 ) %>%
    rename(TAC = `sum`)

```


# Functional stability

Functional stability is calculated using total percentage cover of all algal species as a proxy for biomass. To calculate stability values we are only interested in data following the perturbation, month 6 onwards. 

## Stability metrics

We calculate 4 different metrics using total algal cover data from the time period following the perturbations (months 6 to 15). 

### Temporal variability 

Temporal variability is calculated as the coefficient of variance (CV; that is, standard deviation divided by the mean) of total algal cover in each experimental plot over time during the pertubation phase. Detrended to remove potentially confounding effects of biomass change over the duration of the experiment.

We run linear models on total algal cover in each plot over time and use the residuals from these models to calculate the CV

```{r format data }

tmp<-functional%>%
  select(Diversity,Plot,Time, TAC,Treatment)%>%
  filter(Time < 13)

tmp = split(tmp,tmp$Plot)  

resids<-lapply(names(tmp),function(X){
  Y <- tmp[[X]]
  A <-residuals(lm(TAC~Time, data = Y))
  B <-Y$Diversity
  B2<-Y$Treatment
  C <-Y$Time
  D <-Y$TAC
  E <-sd(A)/mean(D)
  data_frame(Plot=X,Residuals=A, Diversity=B, Treatment = B2, Time=C, TAC =D, Temp.Var=E)
})

Temp_Var<-lapply(resids,function(X){
  X[1,]
}) %>% 
  Reduce("rbind",.)%>% 
  select(Plot,Diversity,Treatment,Temp.Var)

```

### Spatial variability 

Spatial variability was calculated as the CV of total algal cover among 
experimental plots within each stressor vs. consumer loss treatment combination on each census during the pertubation phase. Detrended to remove potentially confounding effects of biomass change over the duration of the experiment. 

So we use the residuals from the previous linear regressions. 
This time we divide SD of the residuals across plots for each time period by the mean total algal cover. 

```{r}

Spatial_Var<- Reduce("rbind",resids)%>%
  select(Time,Plot,Diversity,Treatment, Residuals,TAC)%>%
  group_by(Time, Diversity, Treatment) %>%
  summarise(Spa.Var = sd(Residuals)/mean(TAC))
  
```

### Resistance

Resistance and resilience are associated with a perturbation, they can only be calculated by comparing algal cover in perturbed treatments to cover within unperturbed treatments. 

Resistance was defined as the log response ratio (LRR) of total algal cover in a perturbed relative to unperturbed plot at th end of the perturbation phase. We calculated the LRR of total algal cover in each perturbed plot relative to the mean cover in unperturbed plots for the corresponding consumer loss treatment, for the final time point (month 12) during the perturbation phase (months 6 - 12). 

```{r}
mean_cover<-functional %>%
   filter (Time == 12 & Nutrients == 'N0' & Sediment == 'S0') %>%
  group_by(Diversity, Time)%>%
  summarise(meanTAC = mean(TAC))
  
cover<-functional %>%
   filter (Time == 12 ) %>%
  select(Diversity,Treatment,Time,Plot,TAC)


LRR_Resist<-left_join(cover,mean_cover)%>%
  mutate(LRR_TAC = log(TAC/meanTAC))%>%
  filter(Treatment != 'A_N0_S0' & Treatment != 'B_N0_S0' & Treatment != 'C_N0_S0' &   Treatment != 'D_N0_S0')%>%
  rename(Resist = LRR_TAC)%>%
 select(Plot, Diversity, Treatment, Resist)

```

### Resilience

Resilience is the slope of linear regression of the log response ratio over time from the end of the pertubation phase to the end of the experiment. Calculating the log difference is equivalent to calculating the rate of relative return, rather than the absolute rate, rendering resilience at least conceptually independent from resistance. 
So we run a lm on LRR in between months 12 and months 15.

```{r}
mean_cover<-functional %>%
   filter (Time > 11 & Nutrients == 'N0' & Sediment == 'S0') %>%
  group_by(Diversity, Time)%>%
  summarise(meanTAC = mean(TAC))

cover<-functional %>%
   filter (Time > 11) %>%
  select(Diversity,Treatment,Time,Plot,TAC)

LRR<-left_join(cover,mean_cover)%>%
  mutate(LRR_TAC = log(TAC/meanTAC))
  
Resil<-lapply(1:nrow(LRR_Resist),function(i){
  X = LRR_Resist[i,]
  tmp =  filter(LRR,Plot == X$Plot)
  tmp<-lm(LRR_TAC~Time,data = tmp)
  coef2 = tmp$coefficients["Time"]
  data_frame(Plot=X$Plot,Resilience=coef2)
})%>% Reduce("rbind",.)

```

We can compile all the stabilty measures. For the few cases where perturbations increased biomass and, therefore, resulted in a positive resistance value, resilience was then multiplied by -1.  

```{r, fig.height=10}

Stability_metrics<-left_join(LRR_Resist,Resil)%>%
  mutate(Resilience = ifelse(Resist >0, Resilience*-1, Resilience))%>%
  select(Plot,Diversity,Treatment,Resist,Resilience)%>%
  gather(key = metric, value = value, -Diversity, -Treatment, -Plot)%>%
  rename(rep = Plot)

Temp_Var<-Temp_Var%>%
gather(key = metric, value = value,  -Diversity, -Treatment, -Plot)%>%
rename(rep = Plot)

Spatial_Var<-Spatial_Var%>%
gather(key = metric, value = value,  -Diversity, -Treatment, -Time)%>%
rename(rep = Time )%>%
ungroup(rep)%>%
mutate(rep = as.factor(rep))

```

# Compositional Stability 

## Stability metrics

For compositional stability, we originally calculated bray-curtis distance matrices from the log10 x +1 transformed species abundance data in PRIMER V6. But have redone all the analysis in R, all metrics were calculated with the aim of being analogous to functional measures, where possible.
As for funtional stability, we calculate 4 different metrics using algal cover data from the time period following the perturbations (months 6 to 15). 

### Temporal variability 

Mean Euclidean distance from each experimental plot, on every census (months 6 to 12), to the plot centroid, based on Bray–Curtis dissimilarity matrices calculated from algal cover data.

```{r}
dat<- data%>%
   filter(Time > 5 & Time < 13)%>%
   unite("Treatment_Time",Treatment, Time, remove = FALSE)

dist_bc <- vegdist(log10(1+dat[9:43]), method = 'bray')
mod <- betadisper(dist_bc, dat$Plot)
dat$dist <- mod$distances

Temp_Var_Comp<- dat  %>%
  group_by(Plot)%>%
  summarise(Temp.Var = mean(dist), Diversity = unique(Diversity), Treatment = unique(Treatment) )

```

### Spatial variability 

Mean Euclidean distance from each experimental plot to their grazer treatment centroid, calculated separately for each census (months 6 to 12), based on Bray–Curtis dissimilarity matrices calculated from algal cover data.

```{r}
dat<- data%>%
   filter(Time > 5 & Time < 13)%>%
   unite("Treatment_Time",Treatment, Time, remove = FALSE)

dist_bc <- vegdist(log10(1+dat[9:43]), method = 'bray')
mod <- betadisper(dist_bc, dat$Treatment_Time)  ####### gives mean distance between plots and their centroid

Spatial_Var_Comp<-aggregate(mod$distances,list(dat$Treatment_Time),mean)%>%
 rename(Spa.Var = x, centroid = Group.1)
```

### Resistance, Resilience

For Resistance & Resilience, we used pairwise distances in the same way as LRR values for functional stability, calculating metrics from the temporal trajectory of these LRR values. As for functional stability, these metrics are all associated with a perturbation and can only be calculated by comparing algal assemblage in perturbed treatments to assemblages in unperturbed treatments. 

Because of heterogeneous dispersions between consumer loss treatments (ANOVA results below), we calculated the log response ratio of the mean Euclidian distance between all plots in a given perturbed treatment and their own centroid and that from a perturbed plot to the centroid of the unperturbed plots in the corresponding consumer loss treatment. i.e. 
ln(mean Euclidian distance between all plots in a given perturbed treatment and their own centroid/Euclidian distance from a perturbed plot to the centroid of the unperturbed plots in the corresponding consumer loss treatment)

This effectively takes into account the variabilty amongst plots for a given consumer loss group.

We calculated this LRR for every perturbed plot at the time point at the end of the pertubation phase and during the three month recovery phase after the perturbations (month 12 - 15). And then calculated the remaining stability metrics in exactly the same way as for functional stability. 

```{r}
dat<- data%>%
   filter(Time > 11) %>%
   unite("Treatment_Time", Treatment, Time, remove = FALSE)%>%
   unite("Treatment_Time_Plot",Treatment, Time, Plot, remove = FALSE)

dat<-dat[order(dat$Treatment_Time_Plot),]
dis <- vegdist(log10(1+dat[10:44 ]), method = 'bray')

mod <- betadisper(dis, dat$Treatment)
anova(mod) ### check for dispersion between treatments
plot(mod)

fullmod <- betadisper(dis, dat$Treatment_Time)

fancier_function <- function(X,Y,Z){
  tmp <- Z$vectors[X,] ### the positions of each plot in all pCoA axis (n of plots -1) 
  tmp.pos <- tmp[Z$eig>=0]   ### the real part
  tmp.neg <- tmp[Z$eig<0]   ### the imaginary part
  
  tmp.cent <- Z$centroids[Y,] ### the positions of each centroid
  tmp.cent.pos <- tmp.cent[Z$eig>=0]
  tmp.cent.neg <- tmp.cent[Z$eig<0]
  
  real.euc <- dist(t(data.frame(tmp.pos,tmp.cent.pos))) ### real distances
  imag.euc<- dist(t(data.frame(tmp.neg,tmp.cent.neg))) ### imaginary distances
  as.vector(sqrt(abs(real.euc^2 - imag.euc^2))) # need the sqrt of the difference between real and imaginary parts following Anderson 2006
}
  
Test<-sapply(1:5, function(X) fancier_function(X,"A_N0_S0_12", fullmod)) # can compare Test vs head(fullmod$distances) to check its working properly

names<-dat$Treatment_Time_Plot %>% as.character() 

## converts Treatment_Time_Plot to Treatment_Time using "regular expressions"
tmp2 <- data.frame(Treatment_Time_Plot=names,centroid=gsub("_[^_]+$", "", names),stringsAsFactors = F) # gsub looks for something that starts with an underscore followed by a single or multiple letter or number at the end of the name and replaces it with "nothing" thus removing the last portion of the sampe name 

tmp2$centroid<-sub("_N[0-1]_S[0-1]_","_N0_S0_",tmp2$centroid) ### converts to unperturbed centroid code 
Test2<-sapply(1:320, function(X) fancier_function(X,tmp2$centroid[X], fullmod)) # now apply the funciton to every row in our mod 2 table for every centroid in our centroid table) 

Distances<-cbind(Test2,tmp2)%>%
 rename(ED = Test2)%>%
   separate(Treatment_Time_Plot, c("Diversity", "Nutrients","Sediment", "Time","Plot"))%>%
  unite("Treatment_Time", Diversity, Nutrients, Sediment, Time, remove = FALSE)

dat<- data%>%
   filter(Time > 11)%>%
   unite("Treatment_Time",Treatment, Time, remove = FALSE)

dist_bc <- vegdist(log10(1+dat[9:43]), method = 'bray')
mod <- betadisper(dist_bc, dat$Treatment_Time)  

Spatial_Var_Comp_recovery<-aggregate(mod$distances,list(dat$Treatment_Time),mean)%>%
 rename(Spa.Var = x, Treatment_Time = Group.1)

LRR_Comp<-left_join(Distances, Spatial_Var_Comp_recovery)%>%
  mutate(LRR_COMP = log(Spa.Var/ED))%>%
  mutate(Time = as.numeric(Time))%>%
  unite(Treatment,c("Diversity", "Nutrients","Sediment"),sep="_", remove = F)%>%
  select(Diversity, Treatment, Time, Plot, ED, Spa.Var, LRR_COMP)
   
LRR_Resist_Comp<-LRR_Comp%>%
  filter(Time == 12)%>%
  filter(Treatment != 'A_N0_S0' & Treatment != 'B_N0_S0' & Treatment != 'C_N0_S0' &   Treatment != 'D_N0_S0')%>%
  rename(Resist =  LRR_COMP)%>%
  select(Plot, Diversity, Treatment, Resist)

Resil_Comp<-lapply(1:nrow(LRR_Resist_Comp),function(i){
  X = LRR_Resist_Comp[i,]
  tmp =  filter(LRR_Comp,Plot == X$Plot)
  tmp<-lm(LRR_COMP~Time,data = tmp)
  coef2 = tmp$coefficients["Time"]
  data_frame(Plot=X$Plot,Resilience=coef2)
})%>% Reduce("rbind",.)           
```

We can compile all the stabilty measures. For the few cases where perturbations increased similarity to control plots and, therefore, resulted in a positive resistance value, resilience was then multiplied by -1.  

```{r, fig.height=10}
Stability_metrics_Comp<-left_join(Resil_Comp,LRR_Resist_Comp)%>%
mutate(Resilience = ifelse(Resist >0, Resilience*-1, Resilience))%>%
  select(Plot,Diversity,Treatment,Resist,Resilience)%>%
  gather(key = metric, value = value, -Diversity, -Treatment, -Plot)%>%
  rename(rep = Plot)

Temp_Var_Comp<-Temp_Var_Comp %>%
  select(Plot,Diversity,Treatment,Temp.Var)%>%
  gather(key = metric, value = value, -Diversity, -Treatment, -Plot)%>%
  rename(rep = Plot)

Spatial_Var_Comp<-Spatial_Var_Comp%>%
  separate(centroid, c("Diversity", "Nutrients","Sediment", "Time"))%>%  
  unite(Treatment,c("Diversity", "Nutrients","Sediment"),sep="_", remove = F)%>%
  select(-Nutrients, -Sediment)%>%
  gather(key = metric, value = value,  -Diversity, -Treatment, -Time)%>%
  rename(rep = Time )%>%
  mutate(rep = as.factor(rep))

```

# Predicted vs observed (raw data) for intact communities 

Here we use raw stability measures instead of contributions 
should rename object "contributions".... as is confusing 

## Functional stability 
```{r}
raw <-rbind(Stability_metrics, Temp_Var,data.frame(Spatial_Var))

test<-raw %>% 
  filter (Diversity == "C")%>% 
  separate(Treatment, c("Diversity", "Nutrients","Sediment"))%>%
  unite(Disturbance,c("Nutrients","Sediment"),sep="_")%>%
  filter(Disturbance != 'N0_S0')

predict<-lapply(test$metric %>% unique,function(i){
  y = test %>%
     filter(metric == i & Disturbance == "N0_S1" & Diversity == "C") %>% nrow
    lapply(c("C"), function(k){
    lapply(c("N0_S1","N1_S0"),function(j){
      x = test %>%
       filter(metric == i & Disturbance == j & Diversity == k) 
      x$value[sample(1:nrow(x),1000,replace = T)]
    }) %>%
      Reduce("+",.) %>%
      data_frame(type = "Predicted", Diversity = k, metric = i, value =. ,n=y) 
  })  %>% Reduce("rbind",.)
}) %>% Reduce("rbind",.)

test<-test%>%
  group_by(metric, Diversity, Disturbance)%>%
  summarise(n = n())%>%
  left_join(test,.)%>%
  rename(type = Disturbance)

predict<-rbind(as_data_frame(test %>%
  filter(type == "N1_S1")%>%
 select (type, Diversity, metric, value, n)), predict)

predict_summary_func<-predict %>%
  group_by(type, Diversity, metric)%>%
  summarise(mean=mean(value),  sd = sd(value), n = unique(n))%>%
  mutate(se = sd/sqrt(n),lower.ci = mean - qt(1 - (0.05 / 2), n - 1) * se, upper.ci = mean + qt(1 - (0.05 / 2), n - 1) * se)%>%
  ungroup(type, Diversity,metric) %>%
  mutate(metric = factor(metric,levels = c( "Temp.Var", "Spa.Var", "Resist", "Resilience")))%>%
  mutate(type = plyr::mapvalues(type, from = c("N1_S1", "Predicted"), to = c("observed","predicted")))%>%
    mutate(metric = plyr::mapvalues(metric, from = c("Temp.Var", "Spa.Var", "Resist", "Resilience"), to = c("Temporal variability", "Spatial variability", "Resistance", "Resilience")))

predict %>% 
  group_by(metric, Diversity, type) %>% 
  summarise(new = sample(value, size = 5)) %>% 
  group_by(metric, Diversity) %>% 
  t_test(new ~ type)

predict %>% 
  group_by(metric, Diversity) %>% 
  t_test(value ~ type)

# non-parametric version gives same results 
predict %>% 
  group_by(metric, Diversity) %>% 
    kruskal_test(value ~ type)

```

for the paper we are only interested in variability as we did not detect significant contribution of consumers to resistance and resilience. 

```{r}
pred_Func_raw<-ggplot(filter(predict_summary_func, metric == "Temporal variability" | metric == "Spatial variability"), aes(x=metric, y=mean)) + 
  geom_errorbar(aes(colour = type, ymin=lower.ci, ymax=upper.ci),      position=position_dodge(0.6), size = 0.7, width = 0.4) +
  geom_point(aes(colour = type),position=position_dodge(0.6), size = 3.5)+
  ylab("Functional stability") +
  xlab("") +
  ylim(0,0.8)+
  theme_classic(base_size = 18)+
  theme(axis.text.x=element_text(angle=20,hjust=0.8, vjust = 1),legend.position = "bottom", legend.title=element_text(size=8),legend.text = element_text(size=8)) + scale_colour_manual(values = c("#FF6666", "dark red"))



pred_Func_raw


```

## Compositional stability 

```{r}
raw_Comp <-rbind(Stability_metrics_Comp, Temp_Var_Comp, Spatial_Var_Comp)%>% 
  group_by(metric)

test<-raw_Comp %>% 
  filter (Diversity == "C")%>% 
  separate(Treatment, c("Diversity", "Nutrients","Sediment"))%>%
  unite(Disturbance,c("Nutrients","Sediment"),sep="_")%>%
  filter(Disturbance != 'N0_S0')

predict_comp<-lapply(test$metric %>% unique,function(i){
  y = test %>%
     filter(metric == i & Disturbance == "N0_S1" & Diversity == "C") %>% nrow
    lapply(c("C"), function(k){
    lapply(c("N0_S1","N1_S0"),function(j){
      x = test %>%
       filter(metric == i & Disturbance == j & Diversity == k) 
      x$value[sample(1:nrow(x),1000,replace = T)]
    }) %>%
      Reduce("+",.) %>%
      data_frame(type = "Predicted", Diversity = k, metric = i, value =. ,n=y) 
  })  %>% Reduce("rbind",.)
}) %>% Reduce("rbind",.)


test<-test%>%
  group_by(metric, Diversity, Disturbance)%>%
  summarise(n = n())%>%
  left_join(test,.)%>%
  rename(type = Disturbance)

predict_comp<-rbind(as_data_frame(test %>%
  filter(type == "N1_S1")%>%
 select (type, Diversity, metric, value, n)), predict_comp)

predict_summary_comp<-predict_comp %>%
  group_by(type, Diversity, metric)%>%
  summarise(mean=mean(value),  sd = sd(value), n = unique(n))%>%
  mutate(se = sd/sqrt(n),lower.ci = mean - qt(1 - (0.05 / 2), n - 1) * se, upper.ci = mean + qt(1 - (0.05 / 2), n - 1) * se)%>%
  ungroup(type, Diversity,metric) %>%
  mutate(metric = factor(metric,levels = c( "Temp.Var", "Spa.Var", "Resist", "Resilience")))%>%
  mutate(type = plyr::mapvalues(type, from = c("N1_S1", "Predicted"), to = c("observed","predicted")))%>%
    mutate(metric= plyr::mapvalues(metric, from = c("Temp.Var", "Spa.Var", "Resist", "Resilience"), to = c("Temporal variability", "Spatial variability", "Resistance", "Resilience")))
```

for the paper we are only interested in variability as we did not detect signifcant contribution of consumers to resistance and resilience. 

```{r}

pred_Comp_raw<-ggplot(filter(predict_summary_comp, metric == "Temporal variability" | metric == "Spatial variability"), aes(x=metric, y=mean)) + 
  geom_errorbar(aes(colour = type, ymin=lower.ci, ymax=upper.ci),      position=position_dodge(0.6), width = 0.4, size = 0.7) +
  geom_point(aes(colour = type),position=position_dodge(0.6), size = 3.5)+
  ylab("Compositional stability") +
  xlab("") +
  ylim(0,0.8)+
  theme_classic(base_size = 18)+
  theme(axis.text.x=element_text(angle=20,hjust=0.8, vjust = 1),legend.position = "bottom", legend.title=element_text(size=8),legend.text = element_text(size=8)) + scale_colour_manual(values = c("#FF6666", "dark red"))

pred_raw <- ggarrange(pred_Func_raw + rremove("xlab"), pred_Comp_raw + rremove("xlab"), heights = c(1, 1), ncol = 2, nrow = 1,common.legend = T, labels = c("(a)", "(b)"))

pred_raw

```

## t tests 

comparing observed vs expected with two-tailed, two-sample t-tests. 

```{r}
predict_comp %>% 
  group_by(metric, Diversity, type) %>% 
  summarise(new = sample(value, size = 5)) %>% 
  group_by(metric, Diversity, type) %>%
  summarise(norm = shapiro.test(x= new)$p.value)

predict_comp %>% 
  group_by(metric, Diversity, type) %>% 
  summarise(new = sample(value, size = 5)) %>% 
  group_by(metric, Diversity) %>% 
  t_test(new ~ type)

predict_comp %>% 
  group_by(metric, Diversity, type) %>%
  summarise(norm = shapiro.test(x = value)$p.value)

predict_comp %>% 
  group_by(metric, Diversity) %>% 
  t_test(value ~ type)

# non-parametric version gives same results 
predict_comp %>% 
  group_by(metric, Diversity) %>% 
    kruskal_test(value ~ type)

```

#Session info 
```{r}
sessionInfo()
```

